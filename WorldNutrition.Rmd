As my first Kaggle project, let's try to figure out if fat content in these food products can be predicted from the presence of other specific common ingredients. For instance, if the labeling doesn't say fat content, but the food tastes salty or sugary sweet, can we predict that the food has higher or lower fat.

```{r, message = FALSE}
# Load packages
library('ggplot2') # visualization
library('ggthemes') # visualization
library('scales') # visualization
library('dplyr') # data manipulation
library('mice') # imputation
library('randomForest') # classification algorithm
```

Load nutrition database

```{r, message=FALSE, warning=FALSE}
train_df <- read.csv("input/en.openfoodfacts.org.products.tsv", sep='\t', stringsAsFactors = FALSE);

#top of the dataset
head(train_df)
#the fields and its contents
names(train_df)
str(train_df)
length(train_df)
colnames(train_df)
#let's see what is the search order for our variables
search()
```
Let's trim down the data to the columns and rows we care about. Our goal is to see what fields are most likely to predict fat content and what values in those fields are most likely to correspond to high fat conent. 
```{r, message=FALSE, warning=FALSE}
slim_df <- subset(train_df, select = c(8, 17, 28, 32, 35, 37, 65))
head(slim_df)
count(slim_df)
slim_df2 <- subset(slim_df, slim_df$energy.from.fat_100g > 0)
head(slim_df2)
count(slim_df2)
```

Let's create a column out of each category. For this to work, the first step is to clean the category names as best we can.

```{r, message=FALSE, warning=FALSE}
#let's remove the case problem by making everything lower case
slim_df2[,5] <- sapply(slim_df2[,5],function(x) tolower(x))

#remove some ugly charaters in the ingredients columns that will confuse our regexeses and which make now sense anyway
slim_df2[,5] <- sapply(slim_df2[,5],function(x) gsub("\\[+","",x))
slim_df2[,5] <- sapply(slim_df2[,5],function(x) gsub("\\*+","",x))
```
The seconds step is to break up the ingredients column which now contains a comma separated list and make column names out of them. Occasionally the list items contain more detail in parenthesis. We will remove these, since they don't make sense in column names. We will need two versions: One string for each ingredient that can be used as a column name and one which can be used as a search string. The first one must have no spaces. The second kind must be a proper substring of the ingredients columns because we are going to use it for searching into it in the next step. 

```{r, message=FALSE, warning=FALSE}
removed_parens = gsub("\\([^\\)]+\\)*","",slim_df2[,5])
all_categories = paste(removed_parens, collapse=',')
category_vector <- strsplit(all_categories, split = '[,.:]')
trimmed_categories <- sapply(category_vector, function(x) gsub("^\\s+|\\s+$", "", x))
cat_not_empties <- trimmed_categories[trimmed_categories != ""]
very_common_cat_not_empties = names(sort(table(cat_not_empties), decreasing = T))[0:20]
```

Now let's add the categories as boolean columns. Here we do the additional cleanup needed for column names.

```{r, message=FALSE, warning=FALSE}
col_names <- c()
for(category in very_common_cat_not_empties){
  column_name <- gsub("\\s+|\\d+", "", category)
  column_name <- gsub("[[:punct:]]", "", column_name)
  if(column_name != ""){
    exp = paste("slim_df2 <- transform(slim_df2, ", column_name, "= as.integer(grepl(\"", category, "\", ingredients_text)))", sep = "")
    eval(parse(text=exp))
    col_names <- append( col_names, column_name) 
  }
}
```
Let's look at what numbers of products have what numbers of fat content.
```{r, message=FALSE, warning=FALSE}
table(slim_df2$energy.from.fat_100g)
```
It makes sense to create three categories of fat content:
```{r, message=FALSE, warning=FALSE}
slim_df2$fat_cat[slim_df2$energy.from.fat_100g > 0 & slim_df2$energy.from.fat_100g <=1000 ] <- 'LOW_FAT'
slim_df2$fat_cat[slim_df2$energy.from.fat_100g > 1000 & slim_df2$energy.from.fat_100g <=2000 ] <- 'MID_FAT'
slim_df2$fat_cat[slim_df2$energy.from.fat_100g > 2000 ] <- 'HIGH_FAT'
table(slim_df2$fat_cat)

slim_df2$fat_cat_n[slim_df2$energy.from.fat_100g > 0 & slim_df2$energy.from.fat_100g <=1000 ] <- 1
slim_df2$fat_cat_n[slim_df2$energy.from.fat_100g > 1000 & slim_df2$energy.from.fat_100g <=2000 ] <- 2
slim_df2$fat_cat_n[slim_df2$energy.from.fat_100g > 2000 ] <- 3

```
Let's look at the distribution of products according to these three fat levels in a more visual way:
```{r, message=FALSE, warning=FALSE}
ggplot(data.frame(slim_df2$fat_cat), aes(x=slim_df2$fat_cat)) + geom_bar()
```
It looks like most foods fall into the low fat category. We are interested in predicting from the ingredients which foods fall into the high fat category:
```{r, message=FALSE, warning=FALSE}
# Set a random seed
set.seed(999)
dependency_list <- as.formula(paste( "factor(fat_cat) ~ ", paste(col_names, collapse = "+")))
# We could have used reformulate above instead of paste
dependency_list
food_rf_model <- randomForest(dependency_list, data = slim_df2)

plot(food_food_rf_model)
legend('topright', colnames(food_rf_model$err.rate), col=1:4, fill=1:4)
```
When we plot this, the overall error rate, the black line falls between 20%-30%. It appears, the lower the fat content the more successfully we can predict it from the other variables. This maybe because the lower the fat content the larger the data set. The red graph is puzzling. Can we not predict high fat content at all from the other ingredients for super fatty foods?

Which ingredients are the best predictors of fat content?

```{r, message=FALSE, warning=FALSE}
importance    <- importance(food_rf_model)
varImportance <- data.frame(Variables = row.names(importance), 
                            Importance = round(importance[ ,'MeanDecreaseGini'],2))

# Create a rank variable based on importance
rankImportance <- varImportance %>%
  mutate(Rank = paste0('#',dense_rank(desc(Importance))))

# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance), 
    y = Importance, fill = Importance)) +
  geom_bar(stat='identity') + 
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
    hjust=0, vjust=0.55, size = 4, colour = 'red') +
  labs(x = 'Variables') +
  coord_flip() + 
  theme_few()
```
This shows us the high importance of water, sugar, and salt. What would be more useful is the likelyhood of any of these co-ocurring with low, medium, or high fat content. Since from above it seems that the error rate is high for anything but the prediction of low fat content, let's see which of these ingredients predicts low fat content.

```{r, message=FALSE, warning=FALSE}
corelation_matrix <- cor(slim_df2[,c("energy.from.fat_100g", "water", "sugar", "salt")])
pairs(corelation_matrix)
```
It looks like whenever any of these ingredients are present, the fat content is very low. When they are not present the fat content is very high. Since the pattern is the same for all three of them, it is more likely that the ingredients data gives an incorrect representation of what is in the food product. For instance, maybe very fatty foods simply don't list water, sugar, and salt and other less regulated ingredients. This means we cannot draw conslusions for fat content, from the presense of other ingredients, such as water, sugar, and salt, specifically.

So the only prediction we can make is that if we see a short ingredient list, then it is likely that the food has higher fat content and that this prediction will only be reasonably accurate for foods in the low fat category, based on the error graph above. For super fatty foods, the data doesn't allow us to make any fat content prediction based on the presence of other ingredients.